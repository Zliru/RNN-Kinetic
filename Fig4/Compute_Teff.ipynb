{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute effective T \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)\n",
    "\n",
    "phi = torch.tanh\n",
    "dt = 0.1\n",
    "steps = 3000\n",
    "num_trials = 200\n",
    "steady_check_interval = 10   \n",
    "steady_threshold = 1e-5      \n",
    "avg_window = 40              \n",
    "\n",
    "def check_steady(kinetic_history,window=3,threshold=1e-5):\n",
    "    if len(kinetic_history) < window *2 :\n",
    "        return False\n",
    "    recent = np.mean(kinetic_history[-window:])\n",
    "    pre = np.mean(kinetic_history[-2*window+1:-window])\n",
    "    return abs(recent - pre) < threshold\n",
    "\n",
    "def Classical_rnn_energy(J, num_trials=num_trials):\n",
    "    kinetic_list = []\n",
    "    for _ in range(num_trials):\n",
    "        x = torch.randn(N, device=device)\n",
    "        kinetic_history = []\n",
    "        steady_reached = False\n",
    "        buffer = []  \n",
    "        for t in range(steps):\n",
    "            dx = -x + J @ phi(x)\n",
    "            x = x + dt * dx\n",
    "            buffer.append((dx**2).mean().item()/2)\n",
    "            if t>1000 and (t + 1) % steady_check_interval == 0:\n",
    "                mean_kin = np.mean(buffer[-avg_window:])\n",
    "                kinetic_history.append(mean_kin)\n",
    "                if check_steady(kinetic_history, threshold=steady_threshold):\n",
    "                    steady_reached = True\n",
    "                    break\n",
    "        if steady_reached:\n",
    "            for _ in range(200):\n",
    "                dx = -x + J @ phi(x)\n",
    "                x = x + dt * dx\n",
    "                kinetic_list.append((dx**2).mean().item()/2)\n",
    "    return np.mean(kinetic_list)\n",
    "\n",
    "def Langevin_dynamics_energy(J, T, num_trials=num_trials):\n",
    "    kinetic_list = []\n",
    "    for _ in range(num_trials):\n",
    "        x = torch.randn(N, device=device)\n",
    "        kinetic_history = []\n",
    "        steady_reached = False\n",
    "        buffer = []\n",
    "        for t in range(steps):\n",
    "            x = x.detach().requires_grad_(True)\n",
    "            inner = -x + J @ phi(x)\n",
    "            E = 0.5 * (inner**2).sum()\n",
    "            gradE, = torch.autograd.grad(E, x)\n",
    "            noise = torch.sqrt(torch.tensor(2*T*dt, device=device)) * torch.randn_like(x)\n",
    "            dx = -gradE * dt + noise\n",
    "            x = x + dx\n",
    "            buffer.append((dx**2).mean().item()/2)\n",
    "            if t>1000 and (t + 1) % steady_check_interval == 0:\n",
    "                mean_kin = np.mean(buffer[-avg_window:])\n",
    "                kinetic_history.append(mean_kin)\n",
    "                if check_steady(kinetic_history, threshold=steady_threshold):\n",
    "                    steady_reached = True\n",
    "                    break\n",
    "        if steady_reached:\n",
    "            for _ in range(200):\n",
    "                x = x.detach().requires_grad_(True)\n",
    "                inner = -x + J @ phi(x)\n",
    "                E = 0.5 * (inner**2).sum()\n",
    "                gradE, = torch.autograd.grad(E, x)\n",
    "                noise = torch.sqrt(torch.tensor(2*T*dt, device=device)) * torch.randn_like(x)\n",
    "                dx = -gradE * dt + noise\n",
    "                x = x + dx\n",
    "                kinetic_list.append((dx**2).mean().item()/2)\n",
    "    return np.mean(kinetic_list)\n",
    "\n",
    "def find_effective_temperature(J, target_energy, T_low=0.05, T_high=0.2, tol=1e-6, max_iter=20):\n",
    "    for i in range(max_iter):\n",
    "        T_mid = 0.5 * (T_low + T_high)\n",
    "        E_mid = Langevin_dynamics_energy(J, T_mid)\n",
    "        print(f\"Iter {i+1}: T_mid={T_mid:.6f}, E_mid={E_mid:.6f}\")\n",
    "        if abs(E_mid - target_energy) < tol:\n",
    "            return T_mid, E_mid\n",
    "        if E_mid > target_energy:\n",
    "            T_high = T_mid\n",
    "        else:\n",
    "            T_low = T_mid\n",
    "    return T_mid, E_mid\n",
    "\n",
    "N = 1000             \n",
    "g = 1.5               \n",
    "torch.manual_seed(1997)\n",
    "N_List = [1000,5000,10000]\n",
    "Teff = []\n",
    "for N in N_List:\n",
    "    J = torch.randn(N, N, device=device) * g / np.sqrt(N)\n",
    "    E_rnn = Classical_rnn_energy(J, num_trials=num_trials)\n",
    "    print(f\"Average kinetic energy (classical RNN): {E_rnn:.5f}\")\n",
    "    T_eff, E_eff = find_effective_temperature(J, E_rnn)\n",
    "    print(f\"\\nEstimated effective temperature: T_eff = {T_eff:.6f}, E = {E_eff:.6f}\")\n",
    "    Teff.append(T_eff)\n",
    "\n",
    "df = pd.DataFrame({ \"N\":N_List, \"T_eff\": Teff})\n",
    "df.to_csv(\"Teff.csv\", index=False)\n",
    "print(\"âœ… Data saved to energy_vs_T.csv\")\n",
    "with open(\"E_rnn_value.txt\", \"w\") as f:\n",
    "    f.write(str(E_rnn))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
